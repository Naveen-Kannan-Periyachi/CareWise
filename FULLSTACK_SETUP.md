# CareWise Bio - Full Stack Setup Guide

Complete setup instructions for the CareWise Bio biomedical research assistant with React frontend and Python backend.

## ğŸš€ Quick Start (3 Steps)

### Step 1: Backend Setup

```bash
# Install Python dependencies
pip install -r requirements.txt

# Install Ollama and pull the model
# Download from https://ollama.com/download
ollama pull llama3.1:8b

# Start Ollama service
ollama serve
```

### Step 2: Start Backend API

```bash
# In a new terminal
python backend_api.py
```

The API will start on http://localhost:8000

### Step 3: Start Frontend

```bash
# In a new terminal
cd frontend
npm install
npm start
```

The app will open at http://localhost:3000

---

## ğŸ“ Complete Project Structure

```
carewise-bio/
â”œâ”€â”€ frontend/                        # React Frontend
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ index.html
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ QueryInput.js       # Search interface
â”‚   â”‚   â”‚   â”œâ”€â”€ ExecutionPlan.js    # Plan visualization
â”‚   â”‚   â”‚   â”œâ”€â”€ AnswerDisplay.js    # LLM answer
â”‚   â”‚   â”‚   â”œâ”€â”€ EvidenceList.js     # Evidence grid
â”‚   â”‚   â”‚   â”œâ”€â”€ EvidenceCard.js     # Individual cards
â”‚   â”‚   â”‚   â””â”€â”€ LoadingSpinner.js   # Loading animation
â”‚   â”‚   â”œâ”€â”€ App.js
â”‚   â”‚   â””â”€â”€ index.js
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ src/carewise/                    # Python Backend
â”‚   â”œâ”€â”€ intelligence/               # Query planning
â”‚   â”œâ”€â”€ data/                       # Data acquisition
â”‚   â””â”€â”€ config/                     # Configuration
â”‚
â”œâ”€â”€ backend_api.py                  # FastAPI server
â”œâ”€â”€ main.py                         # CLI interface
â”œâ”€â”€ requirements.txt
â””â”€â”€ FULLSTACK_SETUP.md             # This file
```

---

## ğŸ”§ Detailed Setup

### Prerequisites

- **Python 3.12+**
- **Node.js 16+** and npm
- **Ollama** (for local LLM)
- **Internet connection** (for API calls)

### Backend Installation

1. **Clone or navigate to project:**

   ```bash
   cd carewise-bio
   ```

2. **Create virtual environment (optional but recommended):**

   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install Python dependencies:**

   ```bash
   pip install -r requirements.txt
   ```

4. **Install and configure Ollama:**

   ```bash
   # Download from https://ollama.com/download
   # After installation:
   ollama pull llama3.1:8b
   ```

5. **Verify installation:**
   ```bash
   python -c "import carewise; print('âœ… Backend installed')"
   ```

### Frontend Installation

1. **Navigate to frontend directory:**

   ```bash
   cd frontend
   ```

2. **Install Node dependencies:**

   ```bash
   npm install
   ```

3. **Verify installation:**
   ```bash
   npm run build
   ```

---

## ğŸ® Running the Application

### Option 1: Full Stack (Recommended)

**Terminal 1 - Ollama:**

```bash
ollama serve
```

**Terminal 2 - Backend API:**

```bash
python backend_api.py
```

**Terminal 3 - Frontend:**

```bash
cd frontend
npm start
```

Access the app at: **http://localhost:3000**

### Option 2: CLI Only (No Frontend)

```bash
ollama serve  # In one terminal
python main.py  # In another terminal
```

---

## ğŸ§ª Testing the Setup

### Test Backend API

```bash
# Check API health
curl http://localhost:8000/

# Test query endpoint
curl -X POST http://localhost:8000/api/query \
  -H "Content-Type: application/json" \
  -d '{"query": "CAR-T trials for melanoma"}'
```

### Test Frontend

1. Open http://localhost:3000
2. Click an example query
3. Verify results display correctly

---

## ğŸ¯ Features

### Frontend Features

âœ… Modern gradient UI with animations  
âœ… Mobile-responsive design  
âœ… 5 pre-loaded example queries  
âœ… Real-time loading animations  
âœ… Expandable evidence cards  
âœ… Color-coded source badges  
âœ… Relevance score visualization  
âœ… Inline citation rendering

### Backend Features

âœ… LLM-powered query planning  
âœ… Multi-source data fetching (PubMed, ClinicalTrials, FDA)  
âœ… Evidence normalization & ranking  
âœ… Grounded answer generation  
âœ… REST API with CORS support  
âœ… Automatic error handling  
âœ… FastAPI documentation

---

## ğŸ“Š API Documentation

Once the backend is running, visit:

- **Interactive API docs**: http://localhost:8000/docs
- **Alternative docs**: http://localhost:8000/redoc

### Main Endpoint

**POST** `/api/query`

Request:

```json
{
  "query": "Any ongoing CAR-T trials for melanoma?"
}
```

Response:

```json
{
  "execution_plan": { ... },
  "answer": { ... },
  "evidence": [ ... ]
}
```

---

## ğŸ› ï¸ Configuration

### Backend Configuration

Edit `src/carewise/config/settings.py`:

```python
PUBMED_API_KEY = "your-key-here"
FDA_API_KEY = "your-key-here"
```

âš ï¸ **Security Note**: Use environment variables in production!

### Frontend Configuration

Edit `frontend/package.json`:

```json
"proxy": "http://localhost:8000"
```

Change if backend runs on different port.

---

## ğŸ“¦ Production Deployment

### Backend

```bash
# Install production dependencies
pip install gunicorn

# Run with Gunicorn
gunicorn backend_api:app -w 4 -k uvicorn.workers.UvicornWorker
```

### Frontend

```bash
cd frontend
npm run build

# Serve static files
npm install -g serve
serve -s build -p 3000
```

Or deploy `frontend/build/` to:

- Netlify
- Vercel
- AWS S3 + CloudFront
- Any static hosting service

---

## ğŸ› Troubleshooting

### "Ollama connection refused"

```bash
# Make sure Ollama is running:
ollama serve

# Test Ollama:
ollama run llama3.1:8b "Hello"
```

### "Module not found: carewise"

```bash
# Install in development mode:
pip install -e .
```

### Frontend can't connect to backend

- Verify backend is running on port 8000
- Check CORS settings in `backend_api.py`
- Check proxy in `frontend/package.json`

### API returns 500 errors

- Check Ollama is running
- Check API keys are valid
- Check internet connection
- View logs in terminal

---

## ğŸ” Example Queries

1. "Any ongoing CAR-T trials for melanoma?"
2. "What are the side effects of Pembrolizumab?"
3. "Latest research on CRISPR gene therapy for sickle cell disease"
4. "Clinical trials for Alzheimer's disease treatment"
5. "Compare chemotherapy and immunotherapy for lung cancer"

---

## ğŸ“ˆ Performance Notes

- **First query**: 10-20 seconds (LLM planning + API calls)
- **Subsequent queries**: 5-15 seconds
- **Evidence items**: Top 5 displayed, expandable to all
- **LLM latency**: 2-5 seconds (Ollama local)

---

## ğŸ“ Tech Stack Summary

### Frontend

- React 18.2
- Axios (HTTP client)
- Lucide React (Icons)
- CSS3 (Animations & Grid)

### Backend

- Python 3.12+
- FastAPI (REST API)
- Ollama + llama3.1:8b (LLM)
- Requests (HTTP)
- PubMed, ClinicalTrials.gov, FDA APIs

---

## ğŸ“ License

MIT License - Built for hackathons and research

---

## ğŸ¤ Support

For issues or questions:

1. Check terminal logs
2. Visit http://localhost:8000/docs for API testing
3. Review this setup guide

**Happy researching! ğŸ§¬**
